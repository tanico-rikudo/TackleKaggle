{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download to..: /Users/macico/.keras/datasets/spa-eng/spa.txt\n"
     ]
    }
   ],
   "source": [
    "# Download the file\n",
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\"\n",
    "print(\"Download to..:\",path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テキスト処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    #正規化；Normalization Form Decompose\n",
    "    #汎用カテゴリ：http://www.unicode.org/reports/tr44/#General_Category_Values\n",
    "    #Mn: \tNonspacing_Mark\ta nonspacing combining mark (zero advance width)\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "####  sentence preprocesser\n",
    "def preprocess_sentence(w):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # eg: \"he is a boy.\" => \"he is a boy .\"\n",
    "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.rstrip().strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # モデルが予測をいつ開始し、いつ終了すれば良いかを知らせるため\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 指定データセットからnum_examples文だけ(enflish , spanish)作る\n",
    "# ある程度分かち書きや正規化などはする。\n",
    "# 1. Remove the accents\n",
    "# 2. Clean the sentences\n",
    "# 3. Return word pairs in the format: [ENGLISH, SPANISH]\n",
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "    \n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go.\tVete.\n",
      "<start> ve . <end> <start> go . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end> <start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n"
     ]
    }
   ],
   "source": [
    "### Sample ###\n",
    "print(io.open(path_to_file, encoding='UTF-8').read().strip().split('\\n')[1])\n",
    "\n",
    "en, sp = create_dataset(path_to_file, None)\n",
    "print(sp[0],en[0])\n",
    "print(sp[-1],en[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.keras.preprocessing.text.Tokenizer(\n",
    "- テキストをトークン化するユーティリティクラス．\n",
    "    - 各テキストを整数の列（各整数はは辞書におけるトークンのインデックス）または単語のカウントやtf-idfなどに基づいて各トークンをバイナリとした係数からなるベクトルに変換することで，テキストコーパスをベクトル化します．\n",
    "- テキストをベクトル化する，または/かつ，テキストをシーケンス（= データセット中でランクi（1から始まる）の単語がインデックスiを持つ単語インデックスのリスト）に変換するクラス．\n",
    "- args\n",
    "    - num_words: 利用する単語の最大数で単語の頻度に基づきます．一般的にはnum_words-1が用いられます．\n",
    "    - filters: テキストからフィルタする文字の要素からなる文字列．デフォルトでは全ての句読点に加えてタブや開業，マイナス，'文字です．\n",
    "    - lower: 真理値．テキストを小文字にするかどうか．\n",
    "    - split: 文字列．単語を分割するセパレータ．\n",
    "    - char_level: Trueなら，全文字はトークンとして扱われます．\n",
    "    - oov_token: 与えられた場合，単語のインデックスに付与され，text_to_sequenceが呼ばれた時に語彙にない単語を入れ替えるために使われます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 複数langに対して、ベクトル化\n",
    "# tensor：　文字列を単純に分割したtensor\n",
    "# tokenizer　：　固定長lang_tokenizer(tokenizerクラス)\n",
    "\n",
    "def tokenize(lang):\n",
    "    # Tokenizerをインスタンス化\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    # インスタンスに文章を与える。\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    \n",
    "#     print(\"#doc : \", lang_tokenizer.document_count)\n",
    "#     print(\"#words in doc : \\n\", lang_tokenizer.word_counts)\n",
    "#     print(\"index of word :\",lang_tokenizer.word_index)\n",
    "\n",
    "    #単語のシーケンス番号（1～）の列を示すベクトルが得られる。\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "#     print(tensor)\n",
    "\n",
    "    #固定長に変換\n",
    "    #最大長指定なし→最大の文字長に合わせる\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "#ベクトル*文章数のテンソルのうち、最大次元数を返却\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Make dataset ####\n",
    "def load_dataset(path, num_examples=None):\n",
    "    # creating data\n",
    "    # get input and clean it , output pair\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    #to tensor\n",
    "    #to tokrenize\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n"
     ]
    }
   ],
   "source": [
    "# Try experimenting with the size of that dataset\n",
    "num_examples = 30000\n",
    "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
    "\n",
    "# Calculate max_length of the target tensors\n",
    "max_length_targ, max_length_inp = \\\n",
    "    max_length(target_tensor), max_length(input_tensor)\n",
    "\n",
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = \\\n",
    "    train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<start> ve . <end>']\n",
      "[[1 2 3 4]]\n",
      "1\n",
      "OrderedDict([('<start>', 1), ('ve', 1), ('.', 1), ('<end>', 1)])\n",
      "{'<start>': 1, 've': 2, '.': 3, '<end>': 4}\n",
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "9 ----> el\n",
      "1144 ----> llevaba\n",
      "5907 ----> jeans\n",
      "5908 ----> puestos\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "14 ----> he\n",
      "99 ----> had\n",
      "2595 ----> jeans\n",
      "44 ----> on\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "### Sample ###\n",
    "print([sp[0]])\n",
    "tensor, lang_tokenizer = tokenize([sp[0]])\n",
    "print(tensor)\n",
    "#入力の文章数\n",
    "print(lang_tokenizer.document_count)\n",
    "#ターゲットの辞書\n",
    "print(lang_tokenizer.word_counts)\n",
    "# 単語ごとに割り当て当てられたインデックス番号\n",
    "print(lang_tokenizer.word_index)\n",
    "\n",
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "##　ちゃんと対応取れているよ！\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "#埋め込み次元\n",
    "embedding_dim = 256\n",
    "#En/decoderにおけるユニット数\n",
    "units = 1024\n",
    "# 辞書サイズ,\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "#文字列の配列をスライスすると、文字列のデータセット\n",
    "#よしなにまとめてくれる\n",
    "#シャッフルで\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "#バッチサイズに区切る\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 11]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Sample ###\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "\n",
    "# どちらもBATCH_SIZE＊(最大文字列長)\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoderの設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エンコーダーは入力文字が各ユニットにどの程度重みをつけるかを計算する。\n",
    "class Encoder(tf.keras.Model):\n",
    "    #vocab_size: 辞書サイズ,\n",
    "    #embedding_dim: 隠れ層サイズ\n",
    "    #enc_units: encodeのユニット数\n",
    "    #batch_sz: バッチサイズ\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        \n",
    "        #埋め込み\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        ## GRU:RNN以上LSTM以下のもの\n",
    "        ## Gated Recurrent Unit\n",
    "        # Glorot の正規分布（Xavier の正規分布とも呼ばれます）による初期化を実施\n",
    "        # https://keras.io/ja/initializers/\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "    #フォーワード計算を行う。\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    # 残りの初期化を行う \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, hidden units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, hidden units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "# vocab_inp_size->embedding_dimに圧縮される\n",
    "# units個だけUnitができる\n",
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "###  サンプル入力 ###\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "# 試しに１バッチだけ入れてみる\n",
    "# Call呼び出し\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "\n",
    "print ('Encoder output shape: (batch size, sequence length, hidden units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, hidden units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attensionの設置 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    #units:コンテキストベクターとしてデコーダに渡すので、decodeerのunit数(もちろんencoderとおなじ)\n",
    "    #BahdanauAttentionを使用\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        #encioder input\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        #decoder input\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        #score\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, query, values):\n",
    "        # query : decoerの隠れ層の状態　： shape == (batch_size, hidden size)だけど\n",
    "        #　行列にする必要があるので、(batch_size, 1, hidden size)とする\n",
    "        #　最終的にqueryはencoderの出力における各言葉(文字列長分)に対して加算される\n",
    "        #　＊＊tf.expand_dims　添字\"axis\"でのサイズ1の次元を加える\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # values: encoderの出力\n",
    "        # values == (batch_size, max_length, hidden size)\n",
    "        \n",
    "        # スコアを self.V に適用するために最後の軸は 1 となる\n",
    "        # self.V に適用する前のテンソル(tanh)の shape は  (batch_size, max_length,  hidden size)\n",
    "        \n",
    "        # Denceは和を計算(1次元)\n",
    "        # ==> Scoreは関連度；　推測したい言葉(の状態)(target)から計算された出力(query：hidden_with_time_axis)を全てのencoder出力(values)から計算される。\n",
    "        # transformerなら内積取るらしい\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(\n",
    "                self.W1(values) + self.W2(hidden_with_time_axis)\n",
    "            )\n",
    "        )\n",
    "        #(batch_size, max_length,  hidden size):言葉の重みについてhidden size分だけ存在するのでソフトマックス\n",
    "        # attention_weights の shape == (batch_size, max_length, 1)\n",
    "        # encoder出力とdecoder隠れ層から現時点における各max_length分のユニット(言葉)に対し、attention_weightが作成される(batch_size分)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # attention_weights の shape == (batch_size, max_length, 1)\n",
    "        # values 　　　　　　　　　　　　== (batch_size, max_length, hidden size)\n",
    "        #　もととなる言葉のencoder出力に計算済みの言葉の重みをかければ、現時点(＝文脈)におけるencoder出力を鑑みた算出される各言葉に対する重みが計算\n",
    "        context_vector = attention_weights * values\n",
    "        \n",
    "        #　axis+1次元目で総和を取る\n",
    "        # context_vector の合計後の shape == (batch_size, hidden_size)\n",
    "        # 各encoder出力において言葉の重みを集約データのどこにattentionを向けるのかを判定\n",
    "        #　ｑuery と　valueで毎回全結合層のアップデートが掛かるので常に更新\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape(context vector): (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n",
      "(64, 1, 1024)\n",
      "(64, 16, 1024)\n"
     ]
    }
   ],
   "source": [
    "###  サンプル入力 ###\n",
    "nb_of_hidden = 10\n",
    "attention_layer = BahdanauAttention(nb_of_hidden)\n",
    "#encodeerのテストで作成済み\n",
    "# sample_hidden:deoderの隠れ層の状態\n",
    "# sample_output:encoder出力\n",
    "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
    "\n",
    "#Contextは各\n",
    "print(\"Attention result shape(context vector): (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))\n",
    "\n",
    "print(tf.expand_dims(sample_hidden, 1).shape)\n",
    "print(sample_output.shape)\n",
    "# W1= tf.keras.layers.Dense(units)\n",
    "W2 = tf.keras.layers.Dense(units)\n",
    "# print(W1(sample_output)) #64,16,1024\n",
    "# print(W2(tf.expand_dims(sample_hidden, 1))) #(64, 1, 1024)\n",
    "# print(W1(sample_output)  + W2(tf.expand_dims(sample_hidden, 1))).shape #(64, 16, 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decoderの設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    #vocab_size: 辞書サイズ(出力側はまた違うサイズ)\n",
    "    #embedding_dim: 隠れ層サイズ\n",
    "    #dec_units: decodeのユニット数\n",
    "    #batch_sz: バッチサイズ\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # アテンション設定\n",
    "        # decoderの隠れ層に対して設置される\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        #　まず、decoderの隠れとencorderのアウトプットからアテンション計算\n",
    "        # context_vector, attention_weightsを得る\n",
    "        # enc_output の shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        # GRUへは直列で渡す\n",
    "        # tf.concat : Negative axis are interpreted as counting from the end of the rank, i.e., axis + rank(values)-th dimension.\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # 結合したベクトルを GRU 層に渡す\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "    \n",
    "    ## decoderは隠れの初期化は不要。：encoderを引き継ぐので、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 4935)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "###  サンプル入力 ###\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),\n",
    "                                      sample_hidden, sample_output)\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オプティマイザと損失関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  adamにする\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Computes the crossentropy loss between the labels and predictions.\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "#mean\n",
    "def loss_function(real, pred):\n",
    "    # element wiseで０でないかを判定\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    # paddingした部分を入力としないように位置をmaskingする\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### チェックポイント（オブジェクトベースの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練\n",
    "- \n",
    "- エンコーダーの出力とエンコーダーの隠れ状態、そしてデコーダーの入力（これが 開始トークン）がデコーダーに渡される\n",
    "- デコーダーは 予測値 と デコーダーの隠れ状態 を返す\n",
    "- つぎにデコーダーの隠れ状態がモデルに戻され、予測値が損失関数の計算に使用される\n",
    "- デコーダーへの次の入力を決定するために Teacher Forcing が使用される\n",
    "- Teacher Forcing は、正解単語 をデコーダーの 次の入力 として使用するテクニックである\n",
    "- 最後に勾配を計算し、それをオプティマイザに与えて誤差逆伝播を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    # デコレータはtf.sessionのようなもの。コレをつけるだけで高速化する\n",
    "    #モデルと振る舞いを組み立てる\n",
    "    loss = 0\n",
    "\n",
    "    #GradientTape とは勾配を求めるためのクラス\n",
    "    #内部でtapeで記録された変数は自動的に\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        #入力をエンコーダーに通すと、エンコーダー出力とエンコーダーの隠れ状態 が返される\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        #状態の共有\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        #1文字ずつdecoderに入れていく\n",
    "        #初期値は'<start>'に相当する辞書index（＊バッチサイズ）\n",
    "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "            # Teacher Forcing を使用 - 正解値を次の入力として供給\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "    #tf.keras.Model.trainable_variablesを呼び出すことで、そのネットワークに含まれる重みをリストとして得られる\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    #得られた変数について、微分→更新\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch,batch_loss.numpy()))\n",
    "            \n",
    "    # 2 エポックごとにモデル（のチェックポイント）を保存\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                           maxlen=max_length_inp,\n",
    "                                                           padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        # 後ほどプロットするためにアテンションの重みを保存\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # 予測された ID がモデルに戻される\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# アテンションの重みをプロットする関数\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x134d096d0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint_dir の中の最後のチェックポイントを復元\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> hace mucho frio aqui . <end>\n",
      "Predicted translation: voted voted voted voted voted voted voted voted voted voted voted \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(u'hace mucho frio aqui.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
