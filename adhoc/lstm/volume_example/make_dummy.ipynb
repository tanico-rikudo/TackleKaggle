{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "\n",
    "import datetime as dt \n",
    "import numpy as np\n",
    "from numpy.random import *\n",
    "\n",
    "st  = dt.datetime(2019,1,1, 9, 0)\n",
    "ed  = dt.datetime(2019,1,31, 9, 0)\n",
    "\n",
    "ls_dt = []\n",
    "lapse = st\n",
    "while True:\n",
    "    if lapse > ed:\n",
    "        break\n",
    "    ls_dt.append(lapse)\n",
    "    lapse += dt.timedelta(minutes=30)\n",
    "\n",
    "ls_code = range(1000,2000)\n",
    "\n",
    "ls_volumeRatio = rand(1000)# for _ in range(10)]\n",
    "\n",
    "df_datetime = pd.DataFrame(ls_dt, columns=['datetime'])\n",
    "df_code = pd.DataFrame(ls_code, columns=['code'])\n",
    "df_vr = pd.DataFrame(ls_volumeRatio, columns=['volumeRatio'])\n",
    "\n",
    "df = pd.concat([df_datetime, df_code], ignore_index=True)\n",
    "\n",
    "ls_df = []\n",
    "for _code in ls_code:\n",
    "#     print(_code)\n",
    "    df_datetime = pd.DataFrame(ls_dt, columns=['datetime'])\n",
    "    df_datetime['volumeRatio'] = rand(df_datetime.shape[0])\n",
    "    df_datetime['code'] = _code\n",
    "    ls_df.append(df_datetime)\n",
    "df = pd.concat(ls_df, axis = 0, ignore_index=True)\n",
    "\n",
    "# set(df.code)\n",
    "\n",
    "df  = df.set_index('datetime')\n",
    "\n",
    "df = df.loc[dt.time(9, 0): dt.time(15,0)]\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dummyA'] = rand(df.shape[0])\n",
    "df['dummyB'] = rand(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['catDummyA'] = np.round(rand(df.shape[0])*10).astype(int)\n",
    "df['catDummyB'] = np.round(rand(df.shape[0])*5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['codeSurlusA'] = df.code%7\n",
    "df['codeSurlusB'] = df.code%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df.datetime.dt.strftime('%w')\n",
    "df['dateSpike'] = df.datetime.dt.strftime('%d').astype(int)//11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dummy_vol.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size is ignored\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "from sklearn.utils import indexable\n",
    "from sklearn.utils.validation import _num_samples, column_or_1d\n",
    "class customTimeSeriesSplit(TimeSeriesSplit):\n",
    "    def __init__(self, n_splits=None, train_size=None, test_size=None, split_type = \"flat\",min_train_size=0):\n",
    "        super().__init__(n_splits)#, max_train_size=None)\n",
    "        self.min_train_size = min_train_size \n",
    "        self.train_size = train_size \n",
    "        self.test_size = test_size \n",
    "        self.n_splits = n_splits\n",
    "        self.split_type = split_type \n",
    "        \n",
    "        if self.split_type == 'flat':\n",
    "            assert not self.n_splits is None , \"n_splits must be set\"\n",
    "            assert not self.train_size is None,\"train_size must be set\"\n",
    "            assert not self.test_size is None, \"test_size must be set\"\n",
    "            if not self.min_train_size is None:\n",
    "                print(\"min_train_size is ignored\")\n",
    "    \n",
    "        if self.split_type  == 'with_min':\n",
    "            assert not self.n_splits is None , \"n_splits must be set\"\n",
    "            assert not self.test_size is None,\"train_size must be set\"\n",
    "            assert not self.min_train_size is None, \"min_train_size must be set\"\n",
    "            if not self.train_size is None:\n",
    "                print(\"train_size is ignored\")\n",
    "        \n",
    "    def get_parameter(self):\n",
    "        print(\"train_size:{0}\".format(self.train_size))\n",
    "        print(\"test_size:{0}\".format(self.test_size))\n",
    "        print(\"n_splits:{0}\".format(self.n_splits))\n",
    "        print(\"min_train_size:{0}\".format(self.min_train_size))\n",
    "        print(\"split_type:{0}\".format(self.split_type))\n",
    "        \n",
    "    def get_splitIndex(self,X):\n",
    "        ls_index = []\n",
    "        for train_index, test_index in self.split(X):\n",
    "            ls_index.append((train_index, test_index))\n",
    "        return ls_index\n",
    "        \n",
    "        \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        \n",
    "        if self.split_type == 'flat':\n",
    "            if n_samples - self.n_splits - self.train_size - self.test_size + 1 < 0:\n",
    "                raise ValueError(\"n_samples({0}) must be more than n_splits({1}) + train_size({3})+ test_size({2}) : \" \\\n",
    "                                 .format(n_samples, self.n_splits, self.test_size, self.train_size))\n",
    "\n",
    "            test_starts = range(n_samples - self.n_splits - self.test_size + 1 ,n_samples - self.test_size + 1,1)\n",
    "\n",
    "            for test_start in test_starts:\n",
    "                yield (indices[(test_start - self.train_size):test_start],\n",
    "                       indices[test_start:test_start + self.test_size])\n",
    "                \n",
    "        if self.split_type  == 'with_min':\n",
    "            \"\"\"\n",
    "            n_splits is changed to n_splits - min_train_size\n",
    "            \"\"\"\n",
    "            if n_samples - self.n_splits < self.min_train_size:\n",
    "                raise(\"n_samples({0}) - n_splits({1}) must be more than min_train_size({2})\".format(n_samples, self.n_splits, self.min_train_size))\n",
    "\n",
    "            test_starts = range(n_samples - self.n_splits - self.test_size + 1 ,n_samples - self.test_size + 1,1)\n",
    "            test_starts = [ test_start for test_start in test_starts if test_start >= self.min_train_size ]\n",
    "            \n",
    "            \n",
    "            for test_start in test_starts:\n",
    "                yield (indices[:test_start],\n",
    "                       indices[test_start:test_start + self.test_size])            \n",
    "                    \n",
    "tscv = customTimeSeriesSplit(n_splits=190, train_size=10, test_size=1, split_type = \"with_min\", min_train_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in tscv.split(range(200,400)):\n",
    "#     print(train_index, test_index)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>volumeRatio</th>\n",
       "      <th>code</th>\n",
       "      <th>dummyA</th>\n",
       "      <th>dummyB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385917</th>\n",
       "      <td>2019-01-01 09:00:00</td>\n",
       "      <td>0.602176</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.897828</td>\n",
       "      <td>0.353214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385918</th>\n",
       "      <td>2019-01-01 09:30:00</td>\n",
       "      <td>0.491290</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.832821</td>\n",
       "      <td>0.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385919</th>\n",
       "      <td>2019-01-01 10:00:00</td>\n",
       "      <td>0.939104</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.577552</td>\n",
       "      <td>0.451552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385920</th>\n",
       "      <td>2019-01-01 10:30:00</td>\n",
       "      <td>0.403138</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.798436</td>\n",
       "      <td>0.674146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385921</th>\n",
       "      <td>2019-01-01 11:00:00</td>\n",
       "      <td>0.053805</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.995179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386303</th>\n",
       "      <td>2019-01-30 13:30:00</td>\n",
       "      <td>0.938733</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.543963</td>\n",
       "      <td>0.822097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386304</th>\n",
       "      <td>2019-01-30 14:00:00</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.367578</td>\n",
       "      <td>0.801516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386305</th>\n",
       "      <td>2019-01-30 14:30:00</td>\n",
       "      <td>0.549977</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.450735</td>\n",
       "      <td>0.696127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386306</th>\n",
       "      <td>2019-01-30 15:00:00</td>\n",
       "      <td>0.053859</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.449724</td>\n",
       "      <td>0.944015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386307</th>\n",
       "      <td>2019-01-31 09:00:00</td>\n",
       "      <td>0.416782</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.277665</td>\n",
       "      <td>0.186640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  datetime  volumeRatio  code    dummyA    dummyB\n",
       "385917 2019-01-01 09:00:00     0.602176  1987  0.897828  0.353214\n",
       "385918 2019-01-01 09:30:00     0.491290  1987  0.832821  0.024793\n",
       "385919 2019-01-01 10:00:00     0.939104  1987  0.577552  0.451552\n",
       "385920 2019-01-01 10:30:00     0.403138  1987  0.798436  0.674146\n",
       "385921 2019-01-01 11:00:00     0.053805  1987  0.007739  0.995179\n",
       "...                    ...          ...   ...       ...       ...\n",
       "386303 2019-01-30 13:30:00     0.938733  1987  0.543963  0.822097\n",
       "386304 2019-01-30 14:00:00     0.001125  1987  0.367578  0.801516\n",
       "386305 2019-01-30 14:30:00     0.549977  1987  0.450735  0.696127\n",
       "386306 2019-01-30 15:00:00     0.053859  1987  0.449724  0.944015\n",
       "386307 2019-01-31 09:00:00     0.416782  1987  0.277665  0.186640\n",
       "\n",
       "[391 rows x 5 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_train_size is ignored\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:   14.0s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   31.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288758\tvalid_0's l2: 0.0833811\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.288977\tvalid_0's l2: 0.0835078\n",
      "[3]\tvalid_0's rmse: 0.289278\tvalid_0's l2: 0.0836819\n",
      "[4]\tvalid_0's rmse: 0.28936\tvalid_0's l2: 0.0837291\n",
      "[5]\tvalid_0's rmse: 0.289607\tvalid_0's l2: 0.0838721\n",
      "[6]\tvalid_0's rmse: 0.289895\tvalid_0's l2: 0.0840391\n",
      "[7]\tvalid_0's rmse: 0.290281\tvalid_0's l2: 0.0842633\n",
      "[8]\tvalid_0's rmse: 0.290359\tvalid_0's l2: 0.0843085\n",
      "[9]\tvalid_0's rmse: 0.290404\tvalid_0's l2: 0.0843343\n",
      "[10]\tvalid_0's rmse: 0.290599\tvalid_0's l2: 0.0844479\n",
      "[11]\tvalid_0's rmse: 0.290685\tvalid_0's l2: 0.0844979\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288758\tvalid_0's l2: 0.0833811\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   23.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288876\tvalid_0's l2: 0.0834495\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289177\tvalid_0's l2: 0.0836232\n",
      "[3]\tvalid_0's rmse: 0.289611\tvalid_0's l2: 0.0838747\n",
      "[4]\tvalid_0's rmse: 0.28992\tvalid_0's l2: 0.0840536\n",
      "[5]\tvalid_0's rmse: 0.290598\tvalid_0's l2: 0.084447\n",
      "[6]\tvalid_0's rmse: 0.29118\tvalid_0's l2: 0.0847856\n",
      "[7]\tvalid_0's rmse: 0.291336\tvalid_0's l2: 0.0848767\n",
      "[8]\tvalid_0's rmse: 0.292134\tvalid_0's l2: 0.0853425\n",
      "[9]\tvalid_0's rmse: 0.292465\tvalid_0's l2: 0.0855356\n",
      "[10]\tvalid_0's rmse: 0.292934\tvalid_0's l2: 0.0858101\n",
      "[11]\tvalid_0's rmse: 0.293355\tvalid_0's l2: 0.0860573\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288876\tvalid_0's l2: 0.0834495\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288816\tvalid_0's l2: 0.0834146\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289122\tvalid_0's l2: 0.0835915\n",
      "[3]\tvalid_0's rmse: 0.289544\tvalid_0's l2: 0.0838356\n",
      "[4]\tvalid_0's rmse: 0.289622\tvalid_0's l2: 0.0838809\n",
      "[5]\tvalid_0's rmse: 0.290168\tvalid_0's l2: 0.0841976\n",
      "[6]\tvalid_0's rmse: 0.290556\tvalid_0's l2: 0.0844229\n",
      "[7]\tvalid_0's rmse: 0.29063\tvalid_0's l2: 0.084466\n",
      "[8]\tvalid_0's rmse: 0.290862\tvalid_0's l2: 0.0846005\n",
      "[9]\tvalid_0's rmse: 0.291305\tvalid_0's l2: 0.0848589\n",
      "[10]\tvalid_0's rmse: 0.291582\tvalid_0's l2: 0.0850201\n",
      "[11]\tvalid_0's rmse: 0.291946\tvalid_0's l2: 0.0852324\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288816\tvalid_0's l2: 0.0834146\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   34.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288952\tvalid_0's l2: 0.083493\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289423\tvalid_0's l2: 0.0837657\n",
      "[3]\tvalid_0's rmse: 0.289955\tvalid_0's l2: 0.084074\n",
      "[4]\tvalid_0's rmse: 0.290008\tvalid_0's l2: 0.0841047\n",
      "[5]\tvalid_0's rmse: 0.29035\tvalid_0's l2: 0.0843034\n",
      "[6]\tvalid_0's rmse: 0.290585\tvalid_0's l2: 0.0844397\n",
      "[7]\tvalid_0's rmse: 0.291304\tvalid_0's l2: 0.0848583\n",
      "[8]\tvalid_0's rmse: 0.291811\tvalid_0's l2: 0.0851537\n",
      "[9]\tvalid_0's rmse: 0.291702\tvalid_0's l2: 0.0850903\n",
      "[10]\tvalid_0's rmse: 0.292285\tvalid_0's l2: 0.0854305\n",
      "[11]\tvalid_0's rmse: 0.292264\tvalid_0's l2: 0.0854184\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288952\tvalid_0's l2: 0.083493\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   25.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288892\tvalid_0's l2: 0.0834586\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289364\tvalid_0's l2: 0.0837318\n",
      "[3]\tvalid_0's rmse: 0.28989\tvalid_0's l2: 0.0840363\n",
      "[4]\tvalid_0's rmse: 0.289951\tvalid_0's l2: 0.0840719\n",
      "[5]\tvalid_0's rmse: 0.290471\tvalid_0's l2: 0.0843732\n",
      "[6]\tvalid_0's rmse: 0.290632\tvalid_0's l2: 0.0844669\n",
      "[7]\tvalid_0's rmse: 0.290938\tvalid_0's l2: 0.0846451\n",
      "[8]\tvalid_0's rmse: 0.291414\tvalid_0's l2: 0.0849219\n",
      "[9]\tvalid_0's rmse: 0.291851\tvalid_0's l2: 0.0851768\n",
      "[10]\tvalid_0's rmse: 0.29229\tvalid_0's l2: 0.0854336\n",
      "[11]\tvalid_0's rmse: 0.292751\tvalid_0's l2: 0.0857033\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288892\tvalid_0's l2: 0.0834586\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288632\tvalid_0's l2: 0.0833086\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.288739\tvalid_0's l2: 0.0833704\n",
      "[3]\tvalid_0's rmse: 0.288837\tvalid_0's l2: 0.0834266\n",
      "[4]\tvalid_0's rmse: 0.289036\tvalid_0's l2: 0.0835421\n",
      "[5]\tvalid_0's rmse: 0.289267\tvalid_0's l2: 0.0836752\n",
      "[6]\tvalid_0's rmse: 0.289452\tvalid_0's l2: 0.0837823\n",
      "[7]\tvalid_0's rmse: 0.28977\tvalid_0's l2: 0.0839667\n",
      "[8]\tvalid_0's rmse: 0.290032\tvalid_0's l2: 0.0841185\n",
      "[9]\tvalid_0's rmse: 0.290331\tvalid_0's l2: 0.0842923\n",
      "[10]\tvalid_0's rmse: 0.290547\tvalid_0's l2: 0.0844178\n",
      "[11]\tvalid_0's rmse: 0.290949\tvalid_0's l2: 0.0846512\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288632\tvalid_0's l2: 0.0833086\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   22.5s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288598\tvalid_0's l2: 0.0832889\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.28871\tvalid_0's l2: 0.0833534\n",
      "[3]\tvalid_0's rmse: 0.288875\tvalid_0's l2: 0.0834487\n",
      "[4]\tvalid_0's rmse: 0.288977\tvalid_0's l2: 0.0835075\n",
      "[5]\tvalid_0's rmse: 0.289172\tvalid_0's l2: 0.0836205\n",
      "[6]\tvalid_0's rmse: 0.289409\tvalid_0's l2: 0.0837574\n",
      "[7]\tvalid_0's rmse: 0.289738\tvalid_0's l2: 0.0839484\n",
      "[8]\tvalid_0's rmse: 0.289946\tvalid_0's l2: 0.0840687\n",
      "[9]\tvalid_0's rmse: 0.290333\tvalid_0's l2: 0.0842932\n",
      "[10]\tvalid_0's rmse: 0.290561\tvalid_0's l2: 0.0844257\n",
      "[11]\tvalid_0's rmse: 0.290877\tvalid_0's l2: 0.0846096\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288598\tvalid_0's l2: 0.0832889\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   28.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288788\tvalid_0's l2: 0.0833986\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.288885\tvalid_0's l2: 0.0834548\n",
      "[3]\tvalid_0's rmse: 0.289124\tvalid_0's l2: 0.0835927\n",
      "[4]\tvalid_0's rmse: 0.289213\tvalid_0's l2: 0.0836441\n",
      "[5]\tvalid_0's rmse: 0.289526\tvalid_0's l2: 0.0838251\n",
      "[6]\tvalid_0's rmse: 0.289691\tvalid_0's l2: 0.0839208\n",
      "[7]\tvalid_0's rmse: 0.290071\tvalid_0's l2: 0.0841414\n",
      "[8]\tvalid_0's rmse: 0.290494\tvalid_0's l2: 0.0843866\n",
      "[9]\tvalid_0's rmse: 0.290707\tvalid_0's l2: 0.0845107\n",
      "[10]\tvalid_0's rmse: 0.291149\tvalid_0's l2: 0.0847675\n",
      "[11]\tvalid_0's rmse: 0.29169\tvalid_0's l2: 0.0850832\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288788\tvalid_0's l2: 0.0833986\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   25.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288701\tvalid_0's l2: 0.0833484\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.288939\tvalid_0's l2: 0.0834857\n",
      "[3]\tvalid_0's rmse: 0.289264\tvalid_0's l2: 0.0836738\n",
      "[4]\tvalid_0's rmse: 0.289673\tvalid_0's l2: 0.0839107\n",
      "[5]\tvalid_0's rmse: 0.289732\tvalid_0's l2: 0.0839447\n",
      "[6]\tvalid_0's rmse: 0.28989\tvalid_0's l2: 0.0840362\n",
      "[7]\tvalid_0's rmse: 0.290052\tvalid_0's l2: 0.08413\n",
      "[8]\tvalid_0's rmse: 0.29013\tvalid_0's l2: 0.0841754\n",
      "[9]\tvalid_0's rmse: 0.290583\tvalid_0's l2: 0.0844383\n",
      "[10]\tvalid_0's rmse: 0.290677\tvalid_0's l2: 0.0844933\n",
      "[11]\tvalid_0's rmse: 0.290819\tvalid_0's l2: 0.0845758\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288701\tvalid_0's l2: 0.0833484\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288762\tvalid_0's l2: 0.0833834\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289292\tvalid_0's l2: 0.0836898\n",
      "[3]\tvalid_0's rmse: 0.289548\tvalid_0's l2: 0.0838383\n",
      "[4]\tvalid_0's rmse: 0.289931\tvalid_0's l2: 0.0840598\n",
      "[5]\tvalid_0's rmse: 0.290544\tvalid_0's l2: 0.0844157\n",
      "[6]\tvalid_0's rmse: 0.291075\tvalid_0's l2: 0.0847248\n",
      "[7]\tvalid_0's rmse: 0.291597\tvalid_0's l2: 0.0850287\n",
      "[8]\tvalid_0's rmse: 0.292271\tvalid_0's l2: 0.0854226\n",
      "[9]\tvalid_0's rmse: 0.292862\tvalid_0's l2: 0.0857683\n",
      "[10]\tvalid_0's rmse: 0.293379\tvalid_0's l2: 0.0860712\n",
      "[11]\tvalid_0's rmse: 0.293595\tvalid_0's l2: 0.086198\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288762\tvalid_0's l2: 0.0833834\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   28.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288769\tvalid_0's l2: 0.0833873\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289043\tvalid_0's l2: 0.0835458\n",
      "[3]\tvalid_0's rmse: 0.289417\tvalid_0's l2: 0.0837622\n",
      "[4]\tvalid_0's rmse: 0.289818\tvalid_0's l2: 0.0839946\n",
      "[5]\tvalid_0's rmse: 0.290004\tvalid_0's l2: 0.0841021\n",
      "[6]\tvalid_0's rmse: 0.290531\tvalid_0's l2: 0.084408\n",
      "[7]\tvalid_0's rmse: 0.290604\tvalid_0's l2: 0.0844509\n",
      "[8]\tvalid_0's rmse: 0.291196\tvalid_0's l2: 0.0847952\n",
      "[9]\tvalid_0's rmse: 0.291447\tvalid_0's l2: 0.0849414\n",
      "[10]\tvalid_0's rmse: 0.291584\tvalid_0's l2: 0.0850211\n",
      "[11]\tvalid_0's rmse: 0.291866\tvalid_0's l2: 0.0851858\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288769\tvalid_0's l2: 0.0833873\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   28.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288732\tvalid_0's l2: 0.083366\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289\tvalid_0's l2: 0.0835209\n",
      "[3]\tvalid_0's rmse: 0.289366\tvalid_0's l2: 0.0837326\n",
      "[4]\tvalid_0's rmse: 0.289781\tvalid_0's l2: 0.0839731\n",
      "[5]\tvalid_0's rmse: 0.289888\tvalid_0's l2: 0.0840352\n",
      "[6]\tvalid_0's rmse: 0.290094\tvalid_0's l2: 0.0841546\n",
      "[7]\tvalid_0's rmse: 0.290311\tvalid_0's l2: 0.0842804\n",
      "[8]\tvalid_0's rmse: 0.290791\tvalid_0's l2: 0.0845597\n",
      "[9]\tvalid_0's rmse: 0.291348\tvalid_0's l2: 0.0848836\n",
      "[10]\tvalid_0's rmse: 0.291537\tvalid_0's l2: 0.084994\n",
      "[11]\tvalid_0's rmse: 0.292134\tvalid_0's l2: 0.085342\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288732\tvalid_0's l2: 0.083366\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   24.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288864\tvalid_0's l2: 0.0834422\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289407\tvalid_0's l2: 0.0837567\n",
      "[3]\tvalid_0's rmse: 0.29008\tvalid_0's l2: 0.0841463\n",
      "[4]\tvalid_0's rmse: 0.290913\tvalid_0's l2: 0.0846304\n",
      "[5]\tvalid_0's rmse: 0.291273\tvalid_0's l2: 0.0848399\n",
      "[6]\tvalid_0's rmse: 0.292212\tvalid_0's l2: 0.0853877\n",
      "[7]\tvalid_0's rmse: 0.292726\tvalid_0's l2: 0.0856887\n",
      "[8]\tvalid_0's rmse: 0.29295\tvalid_0's l2: 0.0858199\n",
      "[9]\tvalid_0's rmse: 0.293879\tvalid_0's l2: 0.086365\n",
      "[10]\tvalid_0's rmse: 0.294406\tvalid_0's l2: 0.0866751\n",
      "[11]\tvalid_0's rmse: 0.294883\tvalid_0's l2: 0.0869558\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288864\tvalid_0's l2: 0.0834422\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   26.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.288894\tvalid_0's l2: 0.0834599\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289342\tvalid_0's l2: 0.0837187\n",
      "[3]\tvalid_0's rmse: 0.290042\tvalid_0's l2: 0.0841243\n",
      "[4]\tvalid_0's rmse: 0.290794\tvalid_0's l2: 0.0845614\n",
      "[5]\tvalid_0's rmse: 0.291701\tvalid_0's l2: 0.0850892\n",
      "[6]\tvalid_0's rmse: 0.292572\tvalid_0's l2: 0.0855984\n",
      "[7]\tvalid_0's rmse: 0.292604\tvalid_0's l2: 0.0856173\n",
      "[8]\tvalid_0's rmse: 0.292802\tvalid_0's l2: 0.085733\n",
      "[9]\tvalid_0's rmse: 0.293759\tvalid_0's l2: 0.0862946\n",
      "[10]\tvalid_0's rmse: 0.29398\tvalid_0's l2: 0.0864243\n",
      "[11]\tvalid_0's rmse: 0.294346\tvalid_0's l2: 0.0866398\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.288894\tvalid_0's l2: 0.0834599\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=3)]: Done 160 out of 160 | elapsed:   23.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.28906\tvalid_0's l2: 0.0835558\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tvalid_0's rmse: 0.289401\tvalid_0's l2: 0.0837531\n",
      "[3]\tvalid_0's rmse: 0.289865\tvalid_0's l2: 0.0840219\n",
      "[4]\tvalid_0's rmse: 0.290002\tvalid_0's l2: 0.084101\n",
      "[5]\tvalid_0's rmse: 0.290559\tvalid_0's l2: 0.0844246\n",
      "[6]\tvalid_0's rmse: 0.291218\tvalid_0's l2: 0.0848077\n",
      "[7]\tvalid_0's rmse: 0.291445\tvalid_0's l2: 0.0849402\n",
      "[8]\tvalid_0's rmse: 0.291506\tvalid_0's l2: 0.0849759\n",
      "[9]\tvalid_0's rmse: 0.29223\tvalid_0's l2: 0.0853984\n",
      "[10]\tvalid_0's rmse: 0.292347\tvalid_0's l2: 0.0854667\n",
      "[11]\tvalid_0's rmse: 0.292434\tvalid_0's l2: 0.0855175\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 0.28906\tvalid_0's l2: 0.0835558\n",
      "Fitting 80 folds for each of 2 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:    6.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-320-25dfa2b3f24f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mXy_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"volumeRatio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 )\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/py37b/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "grid_param ={'n_estimators':[1000],'max_depth':[4],'num_leaves':[15,3],'learning_rate':[0.1]}\n",
    "#モデルの作成、各種ハイパラメータの指定\n",
    "\n",
    "train_days = 100\n",
    "test_days = 291\n",
    "min_train_days = 20\n",
    "\n",
    "\n",
    "Xy = df[df.code == 1987]\n",
    "tscv = customTimeSeriesSplit(\n",
    "    n_splits=test_days, train_size=train_days, test_size=1,  split_type = \"flat\")\n",
    "\n",
    "for train_index, test_index in tscv.split(Xy):\n",
    "    \n",
    "    Xy_train_valid = Xy.iloc[train_index]\n",
    "    Xy_test = Xy.iloc[test_index]\n",
    "    \n",
    "    Xy_train_\n",
    "    \n",
    "    \n",
    "    \n",
    "    bst = lgb.LGBMRegressor(\n",
    "                            num_leaves = 31,\n",
    "                            learning_rate=0.01,\n",
    "                            min_child_samples=10,\n",
    "                            n_estimators=1000,\n",
    "                            max_depth=-1,\n",
    "                            )\n",
    "    fit_params={'early_stopping_rounds':10, \n",
    "                'eval_metric' : 'rmse', \n",
    "                'eval_set' : [(df[[\"dummyA\",\"dummyB\"]], df[\"volumeRatio\"])]\n",
    "               }\n",
    "\n",
    "    cv_clf = GridSearchCV(\n",
    "                bst, # 識別器\n",
    "                grid_param, # 最適化したいパラメータセット \n",
    "                cv = customTimeSeriesSplit(\n",
    "                    n_splits=len(train_index)-min_train_days, test_size=1, \n",
    "                    split_type = \"with_min\", min_train_size=min_train_days),\n",
    "                scoring = 'neg_mean_squared_error',\n",
    "                verbose = 0,\n",
    "                n_jobs=3\n",
    "                )\n",
    "\n",
    "    cv_clf.fit(\n",
    "                Xy_train[[\"dummyA\",\"dummyB\"]], \n",
    "                Xy_train[\"volumeRatio\"],\n",
    "                **fit_params,\n",
    "                verbose = 0\n",
    "                )\n",
    "    \n",
    "    y_pred = cv_clf.best_estimator_.predict(Xy_test[[\"dummyA\",\"dummyB\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48948557])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.tsa.api import VAR  \n",
    "import lightgbm as lgb\n",
    "grid_param ={'n_estimators':[1000],'max_depth':[4],'num_leaves':[15,3],'learning_rate':[0.1]}\n",
    "#モデルの作成、各種ハイパラメータの指定\n",
    "\n",
    "train_days = 100\n",
    "test_days = 291\n",
    "min_train_days = 20\n",
    "lag = 2\n",
    "\n",
    "Xy = df[df.code == 1987]\n",
    "tscv = customTimeSeriesSplit(\n",
    "    n_splits=test_days, train_size=train_days, test_size=1,  split_type = \"flat\")\n",
    "\n",
    "for train_index, test_index in tscv.split(Xy):\n",
    "    \n",
    "    Xy_train = Xy.iloc[train_index]\n",
    "    Xy_test = Xy.iloc[test_index]\n",
    "    \n",
    "    model = VAR(data)\n",
    "    results = model.fit(lag)#####\n",
    "    results.forecast(Xy_train.values[-2:], 5)####\n",
    "    \n",
    "    y_pred = cv_clf.best_estimator_.predict(Xy_test[[\"dummyA\",\"dummyB\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_train_size is ignored\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'execVAR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-321-dbaba20419d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mXy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecVAR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXy_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'execVAR' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from statsmodels.tsa.api import VAR  \n",
    "import statsmodels.formula.api as smf\n",
    "import lightgbm as lgb\n",
    "grid_param ={'n_estimators':[1000],'max_depth':[4],'num_leaves':[15,3],'learning_rate':[0.1]}\n",
    "#モデルの作成、各種ハイパラメータの指定\n",
    "\n",
    "train_days = 100\n",
    "test_days = 291\n",
    "min_train_days = 20\n",
    "# lag = 2\n",
    "\n",
    "Xy = df[df.code == 1987]\n",
    "tscv = customTimeSeriesSplit(\n",
    "    n_splits=test_days, train_size=train_days, test_size=1,  split_type = \"flat\")\n",
    "\n",
    "######## ls_cols ########\n",
    "for train_index, test_index in tscv.split(Xy):\n",
    "    \n",
    "\n",
    "    for \n",
    "    execVAR(Xy_vars,i_target):\n",
    "    \n",
    "    Xy_train = Xy.iloc[train_index]\n",
    "    Xy_test = Xy.iloc[test_index]\n",
    "    \n",
    "    y_pred = execVAR(Xy_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 2\n",
    "def execVAR(Xy_vars,i_target):\n",
    "    model = VAR(Xy_vars)\n",
    "    results = model.fit(lag)#####\n",
    "    pred = results.forecast(data.values[-2:],i_target)####\n",
    "    return pred\n",
    "\n",
    "def execMLR(X_train,y_train,X_test):\n",
    "    model = sm.OLS(y_train, X_train)\n",
    "    model = model.fit()\n",
    "    pred = model.predict(X_test)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ols も　var もなにのカラムをつかうかはvalidで証明している必要があるので、データをGBDT同様に分割"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
